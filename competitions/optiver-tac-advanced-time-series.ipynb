{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57891,"databundleVersionId":7056235,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:45:00.860386Z","iopub.execute_input":"2023-12-17T17:45:00.860957Z","iopub.status.idle":"2023-12-17T17:45:01.331737Z","shell.execute_reply.started":"2023-12-17T17:45:00.860908Z","shell.execute_reply":"2023-12-17T17:45:01.330132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport lightgbm as lgb\nimport plotly.express as px\nfrom itertools import combinations\nimport os\nimport gc\nimport sys\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom warnings import simplefilter\nsimplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:45:16.487128Z","iopub.execute_input":"2023-12-17T17:45:16.487664Z","iopub.status.idle":"2023-12-17T17:45:33.921340Z","shell.execute_reply.started":"2023-12-17T17:45:16.487630Z","shell.execute_reply":"2023-12-17T17:45:33.919721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the optiver files\n\ntrain_df = pd.read_csv(\"/kaggle/input/optiver-trading-at-the-close/train.csv\")\nrevealed_targets_df = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv')\ntest_df = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv')\nsample_submission_df = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/example_test_files/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:46:04.314122Z","iopub.execute_input":"2023-12-17T17:46:04.314598Z","iopub.status.idle":"2023-12-17T17:46:27.906553Z","shell.execute_reply.started":"2023-12-17T17:46:04.314560Z","shell.execute_reply":"2023-12-17T17:46:27.905283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Overview of the optiver data\n\ntrain_df.sort_values(by=['stock_id','date_id'],inplace=True)\ntrain_df.loc[train_df['stock_id']==0]\n\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:47:09.948167Z","iopub.execute_input":"2023-12-17T17:47:09.948602Z","iopub.status.idle":"2023-12-17T17:47:11.632867Z","shell.execute_reply.started":"2023-12-17T17:47:09.948566Z","shell.execute_reply":"2023-12-17T17:47:11.631626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_engineering(df):\n    \n    # Removing data that's not in the actual test data in the API\n    cols = [c for c in df.columns if c not in ['row_id', 'time_id', 'target']]\n    df = df[cols]\n    \n    # Here we calculate spread differentials and spread ratios\n    df['bid_minus_ask_size'] = df['bid_size'] - df['ask_size']\n    df['bid_ask_size_ratio'] = df['bid_size'] / df['ask_size']\n    df['bid_ask_price_ratio'] = df['bid_size'] / df['ask_size']\n    df['bid_minus_ask_spread'] = df['ask_price'] - df['bid_price']\n    \n    # Next, we calculate median, matched sizes, bid and ask sizes\n    stock_median_ask_size = df.groupby(['stock_id'])['ask_size'].median()\n    stock_median_bid_size = df.groupby(['stock_id'])['bid_size'].median()\n    stock_median_imbalance_size = df.groupby(['stock_id'])['imbalance_size'].median()\n    \n    day_median_ask_size = df.groupby(['date_id'])['ask_size'].median()\n    day_median_bid_size = df.groupby(['date_id'])['bid_size'].median()\n    day_median_imbalance_size = df.groupby(['date_id'])['imbalance_size'].median()\n    \n    day_stock_ask_median_ask_size = df.groupby(['date_id', 'stock_id'])['ask_size'].median()\n    day_stock_bid_median_ask_size = df.groupby(['date_id', 'stock_id'])['bid_size'].median()\n    day_stock_imbalance_median_ask_size = df.groupby(['date_id', 'stock_id'])['imbalance_size'].median()\n    \n    df = df.merge(stock_median_ask_size, how='left', left_on='stock_id', right_index=True, suffixes=('', '_stock_median'))\n    df = df.merge(stock_median_bid_size, how='left', left_on='stock_id', right_index=True, suffixes=('', '_stock_median'))\n    df = df.merge(stock_median_imbalance_size, how='left', left_on='stock_id', right_index=True, suffixes=('', '_stock_median'))\n    \n    # Lag features\n    lag_features = ['bid_size', 'ask_size', 'imbalance_size']\n    for feature in lag_features:\n        df[f'{feature}_lag_1'] = df.groupby(['stock_id'])[feature].shift(1)\n    \n    # Rolling statistics\n    rolling_features = ['bid_size', 'ask_size', 'imbalance_size']\n    window_sizes = [5, 10, 20]\n    for feature in rolling_features:\n        for window_size in window_sizes:\n            df[f'{feature}_rolling_mean_{window_size}'] = df.groupby(['stock_id'])[feature].transform(lambda x: x.rolling(window=window_size).mean())\n            df[f'{feature}_rolling_std_{window_size}'] = df.groupby(['stock_id'])[feature].transform(lambda x: x.rolling(window=window_size).std())\n    \n    # Advanced time series features\n    df['return'] = df['wap'].pct_change()\n    df['log_return'] = np.log(1 + df['return'])\n    df['cumulative_return'] = (1 + df['return']).cumprod()\n    \n    # Autocorrelation features\n    autocorr_features = ['bid_size', 'ask_size', 'imbalance_size']\n    for feature in autocorr_features:\n        df[f'{feature}_autocorr_1'] = df.groupby(['stock_id'])[feature].transform(lambda x: x.autocorr(1))\n        df[f'{feature}_autocorr_3'] = df.groupby(['stock_id'])[feature].transform(lambda x: x.autocorr(3))\n    \n    # Drop unnecessary columns\n    df.drop(columns=['date_id'], axis=1, inplace=True)\n    \n    gc.collect()\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:47:23.018678Z","iopub.execute_input":"2023-12-17T17:47:23.019163Z","iopub.status.idle":"2023-12-17T17:47:23.040654Z","shell.execute_reply.started":"2023-12-17T17:47:23.019124Z","shell.execute_reply":"2023-12-17T17:47:23.039160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train_df['target'].values\nX = feature_engineering(train_df)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:47:42.082566Z","iopub.execute_input":"2023-12-17T17:47:42.083859Z","iopub.status.idle":"2023-12-17T17:48:03.476147Z","shell.execute_reply.started":"2023-12-17T17:47:42.083784Z","shell.execute_reply":"2023-12-17T17:48:03.474719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.tail(10)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:48:07.196533Z","iopub.execute_input":"2023-12-17T17:48:07.197027Z","iopub.status.idle":"2023-12-17T17:48:07.238967Z","shell.execute_reply.started":"2023-12-17T17:48:07.196992Z","shell.execute_reply":"2023-12-17T17:48:07.237460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.columns","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:48:12.740463Z","iopub.execute_input":"2023-12-17T17:48:12.740977Z","iopub.status.idle":"2023-12-17T17:48:12.751218Z","shell.execute_reply.started":"2023-12-17T17:48:12.740921Z","shell.execute_reply":"2023-12-17T17:48:12.749332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = lgb.LGBMRegressor(objective='mae', \n                      n_estimators=600, \n                      random_state=51, num_threads=4, num_leaves=35)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:48:37.040745Z","iopub.execute_input":"2023-12-17T17:48:37.041179Z","iopub.status.idle":"2023-12-17T17:48:37.047159Z","shell.execute_reply.started":"2023-12-17T17:48:37.041143Z","shell.execute_reply":"2023-12-17T17:48:37.045720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:48:48.728907Z","iopub.execute_input":"2023-12-17T17:48:48.729432Z","iopub.status.idle":"2023-12-17T17:56:24.504815Z","shell.execute_reply.started":"2023-12-17T17:48:48.729391Z","shell.execute_reply":"2023-12-17T17:56:24.503310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(model.feature_importances_)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:56:31.444340Z","iopub.execute_input":"2023-12-17T17:56:31.444846Z","iopub.status.idle":"2023-12-17T17:56:31.455670Z","shell.execute_reply.started":"2023-12-17T17:56:31.444808Z","shell.execute_reply":"2023-12-17T17:56:31.454159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_imp = pd.Series(model.feature_importances_, index=X.columns).sort_values()\nprint('Columns with poor contribution', feature_imp[feature_imp<15].index)\nfig = px.bar(x=feature_imp, y=feature_imp.index, orientation='h')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:56:34.492437Z","iopub.execute_input":"2023-12-17T17:56:34.492982Z","iopub.status.idle":"2023-12-17T17:56:36.682285Z","shell.execute_reply.started":"2023-12-17T17:56:34.492934Z","shell.execute_reply":"2023-12-17T17:56:36.680851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optiver2023\nenv = optiver2023.make_env()\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:56:54.699466Z","iopub.execute_input":"2023-12-17T17:56:54.699936Z","iopub.status.idle":"2023-12-17T17:56:54.719928Z","shell.execute_reply.started":"2023-12-17T17:56:54.699899Z","shell.execute_reply":"2023-12-17T17:56:54.718428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counter = 0\nY_actual = pd.DataFrame()\nfor (test, revealed_targets, sample_prediction) in iter_test:\n    x = feature_engineering(test)\n    x.drop(\"currently_scored\", axis=1, inplace=True)\n    sample_prediction['target'] = model.predict(x)\n    env.predict(sample_prediction)\n    #concat\n    Y_actual = pd.concat( [Y_actual, revealed_targets])\n    counter += 1","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:56:59.393780Z","iopub.execute_input":"2023-12-17T17:56:59.394240Z","iopub.status.idle":"2023-12-17T18:02:35.670081Z","shell.execute_reply.started":"2023-12-17T17:56:59.394206Z","shell.execute_reply":"2023-12-17T18:02:35.668606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}